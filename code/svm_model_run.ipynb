{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text_cleaning_utils import TextCleaner\n",
    "\n",
    "def preprocess_text_for_svm(df, text_column):\n",
    "    \"\"\"\n",
    "    Preprocess text data for SVM model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame containing the text data\n",
    "    text_column : str\n",
    "        Name of the column containing text to be processed\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        DataFrame with preprocessed text and tokenized embeddings\n",
    "    \"\"\"\n",
    "    # Initialize text cleaner\n",
    "    text_cleaner = TextCleaner()\n",
    "    \n",
    "    # Apply text cleaning functions\n",
    "    processed_text = (df[text_column]\n",
    "                     .apply(text_cleaner.remove_digits)\n",
    "                     .apply(text_cleaner.remove_english_and_special_chars)\n",
    "                     .apply(text_cleaner.remove_stopwords)\n",
    "                     .apply(text_cleaner.remove_emojis))\n",
    "    \n",
    "    # Create a copy of the dataframe to avoid SettingWithCopyWarning\n",
    "    processed_df = df.copy()\n",
    "    processed_df[text_column] = processed_text\n",
    "    \n",
    "    # Tokenize the clean text\n",
    "    tokenizer = SentencepieceTokenizer()\n",
    "    processed_df['tokenized_text'] = processed_df[text_column].apply(\n",
    "        lambda x: tokenizer.tokenize(x) if isinstance(x, str) else []\n",
    "    )\n",
    "    \n",
    "    # Get embeddings for each token\n",
    "    fast_text_embedding = BengaliFasttext()\n",
    "    processed_df['embeddings'] = processed_df['tokenized_text'].apply(\n",
    "        lambda tokens: get_embeddings(tokens, fast_text_embedding)\n",
    "    )\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "cleaned_comments_dataset = pd.read_csv(\n",
    "    \"../dataset/cleaned_comments_dataset.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    engine=\"pyarrow\",\n",
    ")\n",
    "\n",
    "only_augmented_comments_dataset = pd.read_csv(\n",
    "    \"../dataset/only_augmented_comments_dataset.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    engine=\"pyarrow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding_dict = {\n",
    "    \"not bully\": 0,\n",
    "    \"religious\": 1,\n",
    "    \"troll\": 2,\n",
    "    \"sexual\": 3,\n",
    "    \"threat\": 4,\n",
    "}\n",
    "\n",
    "cleaned_comments_dataset[\"label\"] = cleaned_comments_dataset[\"label\"].map(\n",
    "    label_encoding_dict\n",
    ")\n",
    "\n",
    "only_augmented_comments_dataset[\"label\"] = only_augmented_comments_dataset[\"label\"].map(\n",
    "    label_encoding_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>হালার পুত মদ খাওয়ার সময় রাতের বেলা মদ খাই দি...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ঘরে শুট কেমন লেগেছে ক্যামেরাতে</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>অরে বাবা টা পাগল</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ক্যাপ্টেন অফ বাংলাদেশ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>পটকা মাছ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43562</th>\n",
       "      <td>হিরো আলম এগিয়ে যাও</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43563</th>\n",
       "      <td>হিরো আলমকে সাপোর্ট অসংখ্য ধন্যবাদ আপনাকে</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43564</th>\n",
       "      <td>হিরো ভাই এগিয়ে য়াও</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43565</th>\n",
       "      <td>হুম ভাও তোমরা এগিয়ে যাও তোমাদের পিছনে আছি</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43566</th>\n",
       "      <td>হ্যালো তোমাদের সাথে চ্যাট</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43567 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  label\n",
       "0      হালার পুত মদ খাওয়ার সময় রাতের বেলা মদ খাই দি...      3\n",
       "1                         ঘরে শুট কেমন লেগেছে ক্যামেরাতে      0\n",
       "2                                       অরে বাবা টা পাগল      0\n",
       "3                                  ক্যাপ্টেন অফ বাংলাদেশ      0\n",
       "4                                               পটকা মাছ      2\n",
       "...                                                  ...    ...\n",
       "43562                                 হিরো আলম এগিয়ে যাও      0\n",
       "43563           হিরো আলমকে সাপোর্ট অসংখ্য ধন্যবাদ আপনাকে      0\n",
       "43564                                 হিরো ভাই এগিয়ে য়াও      0\n",
       "43565          হুম ভাও তোমরা এগিয়ে যাও তোমাদের পিছনে আছি      0\n",
       "43566                          হ্যালো তোমাদের সাথে চ্যাট      0\n",
       "\n",
       "[43567 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>খানকিরা জানে খানকি বিত্তি কিভাবে আল্লাহতালা নর...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>তুই বড়যাত্রা এসেছ জুতা দেখেশিসতাহলে তর মাবাপের...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>এক সাক্ষাৎকারে মেয়েটি বলেছে বিশ্বাস না। ইসলাম...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>নাস্তিকের প্রার্থনা</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>আজকাল লম্পট অশিক্ষিত ব্যক্তি মুখ বের আনে শীঘ্র...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>দেশ রুপার বিতাড়িত</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>জুতাটা কপালে মেরেছি।</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>সেফু নামক এক ইসলাম বিদ্বেষীর কুরআন রাসুল সঃ অপ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>জুতা মেরে গরু দান পুকি মেরে দিলা।</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>মারুন রে জাহেদ জুতা</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6081 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     খানকিরা জানে খানকি বিত্তি কিভাবে আল্লাহতালা নর...      1\n",
       "1     তুই বড়যাত্রা এসেছ জুতা দেখেশিসতাহলে তর মাবাপের...      4\n",
       "2     এক সাক্ষাৎকারে মেয়েটি বলেছে বিশ্বাস না। ইসলাম...      1\n",
       "3                                   নাস্তিকের প্রার্থনা      1\n",
       "4     আজকাল লম্পট অশিক্ষিত ব্যক্তি মুখ বের আনে শীঘ্র...      1\n",
       "...                                                 ...    ...\n",
       "6076                                  দেশ রুপার বিতাড়িত      4\n",
       "6077                               জুতাটা কপালে মেরেছি।      4\n",
       "6078  সেফু নামক এক ইসলাম বিদ্বেষীর কুরআন রাসুল সঃ অপ...      4\n",
       "6079                  জুতা মেরে গরু দান পুকি মেরে দিলা।      4\n",
       "6080                                মারুন রে জাহেদ জুতা      4\n",
       "\n",
       "[6081 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_augmented_comments_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Tokenization and Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnlp import SentencepieceTokenizer\n",
    "from bnlp.embedding.fasttext import BengaliFasttext\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SentencepieceTokenizer()\n",
    "fast_text_embedding = BengaliFasttext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(tokens):\n",
    "    # Initialize an empty list to store embeddings for each token\n",
    "    embeddings = []\n",
    "\n",
    "    # Get embedding for each token in the token list\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            embedding = fast_text_embedding.get_word_vector(token)\n",
    "            embeddings.append(embedding)\n",
    "        except:\n",
    "            # If token doesn't have an embedding, skip it\n",
    "            continue\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Convert list of token embeddings to a single fixed-length vector by taking the mean\n",
    "def get_mean_embedding(embeddings_list):\n",
    "    if not embeddings_list:  # Handle empty lists\n",
    "        return np.zeros(100)  # Fasttext embeddings are of length 100\n",
    "    return np.mean(embeddings_list, axis=0)\n",
    "\n",
    "\n",
    "def tokenize_and_generate_embeddings(text_series: pd.Series):\n",
    "\n",
    "    tokenized_series = text_series.apply(\n",
    "        lambda x: tokenizer.tokenize(x) if isinstance(x, str) else []\n",
    "    )\n",
    "\n",
    "    print(\"Tokenized Series\", tokenized_series)\n",
    "\n",
    "    embeddings_series = tokenized_series.apply(lambda tokens: get_embeddings(tokens))\n",
    "\n",
    "    print(\"Embeddings Series\", embeddings_series)\n",
    "\n",
    "    mean_embedding = get_mean_embedding(embeddings_list=embeddings_series)\n",
    "\n",
    "    print(\"Mean Embedding\", mean_embedding)\n",
    "\n",
    "    return mean_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evaluate_model_performance(model, X_test, y_test, class_names=None):\n",
    "    \"\"\"\n",
    "    Evaluates and prints various performance metrics for a classification model\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : trained classifier model with predict method\n",
    "        The trained model to evaluate\n",
    "    X_test : array-like\n",
    "        Test features\n",
    "    y_test : array-like\n",
    "        True labels for test data\n",
    "    class_names : list, optional\n",
    "        Names of the classes (used for confusion matrix)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing all calculated metrics\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Model Performance Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(len(np.unique(y_test)))]\n",
    "\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Return metrics as dictionary\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# class_names = [\"not bully\", \"religious\", \"troll\", \"sexual\", \"threat\"]\n",
    "# metrics = evaluate_model_performance(svm_model, test_X_vectors, test_y, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Run on Original Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(\n",
    "    cleaned_comments_dataset[\"comment\"],\n",
    "    cleaned_comments_dataset[\"label\"],\n",
    "    test_size=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Series 9824     [▁নাস্তিক, ▁তোমার, ে, ▁ভাল, ▁জানতাম, ▁আসলে, ▁ভ...\n",
      "24052                             [▁সাজ, লে, ▁ভালো, ▁লাগে]\n",
      "14137    [▁, কন্ডিশন, ▁চো, দা, ও, ▁যদি, ভুল, ▁কর, ছ, স,...\n",
      "27179    [▁বেগম, ▁খালেদা, ▁জিয়া, ▁শামীম, ▁ইস্কান্দার, ...\n",
      "34524                                            [▁বা, রা]\n",
      "                               ...                        \n",
      "7312                                       [▁এই, টা, ▁গান]\n",
      "23542    [▁আক্রমন, ▁পর, কালে, ▁বিশ্বাস, ▁পর, কালে, ▁বিশ...\n",
      "1190     [▁শয়তানের, ▁ছা, মা, ▁আম্, মে, ▁আম্, মের, ▁বা,...\n",
      "29064    [▁মুসলমানের, ▁দেশে, ▁বাস, ▁নাস্তিক, ▁টানা, ▁টা...\n",
      "9800     [▁তুই, ▁মরে, ▁দেখ, ▁পরকাল, ▁জিনিস, ৷, তু, ই, ▁...\n",
      "Name: comment, Length: 34853, dtype: object\n",
      "Embeddings Series 9824     [[-0.19078824, 0.25596625, -0.33603647, 0.0735...\n",
      "24052    [[0.2232472, -0.30901948, 0.21364312, 0.510633...\n",
      "14137    [[-0.25709486, -1.3109767, -0.23048481, -0.234...\n",
      "27179    [[0.45657516, -0.080844015, -0.027284317, 0.72...\n",
      "34524    [[-1.1272352, 0.8112111, 0.392819, -0.01527650...\n",
      "                               ...                        \n",
      "7312     [[-0.21231034, 0.081766054, 0.3497004, -0.0172...\n",
      "23542    [[0.0019526563, -0.3529937, 1.0439119, -0.2952...\n",
      "1190     [[0.44946033, 0.10797865, -0.30106565, 0.10116...\n",
      "29064    [[0.7630402, -0.4064947, -0.84281677, 0.136060...\n",
      "9800     [[-0.23923002, -0.72272646, 0.061348148, -0.24...\n",
      "Name: comment, Length: 34853, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_5320\\1899648673.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embeddings_train_X = tokenize_and_generate_embeddings(trainX)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_5320\\1097224417.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(text_series)\u001b[39m\n\u001b[32m     32\u001b[39m     embeddings_series = tokenized_series.apply(\u001b[38;5;28;01mlambda\u001b[39;00m tokens: get_embeddings(tokens))\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m     print(\u001b[33m\"Embeddings Series\"\u001b[39m, embeddings_series)\n\u001b[32m     35\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     mean_embedding = get_mean_embedding(embeddings_list=embeddings_series)\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m     print(\u001b[33m\"Mean Embedding\"\u001b[39m, mean_embedding)\n\u001b[32m     39\u001b[39m \n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_5320\\1097224417.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(embeddings_list)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m get_mean_embedding(embeddings_list):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m embeddings_list:  \u001b[38;5;66;03m# Handle empty lists\u001b[39;00m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.zeros(\u001b[32m100\u001b[39m)  \u001b[38;5;66;03m# Fasttext embeddings are of length 100\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(embeddings_list, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[32md:\\SWE Class\\Research\\Bangla-Cyberbullying\\bangla-cyberbullying\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1464\u001b[39m     @final\n\u001b[32m   1465\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __nonzero__(self) -> NoReturn:\n\u001b[32m-> \u001b[39m\u001b[32m1466\u001b[39m         raise ValueError(\n\u001b[32m   1467\u001b[39m             f\"The truth value of a {type(self).__name__} is ambiguous. \"\n\u001b[32m   1468\u001b[39m             \u001b[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[39m\n\u001b[32m   1469\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "embeddings_train_X = tokenize_and_generate_embeddings(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
