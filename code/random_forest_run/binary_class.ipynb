{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bangla Cyberbullying Classification with Random Forest\n",
    "\n",
    "This notebook implements a random forest classifier for multi-class classification of Bangla cyberbullying text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from bnlp import SentencepieceTokenizer\n",
    "from bnlp.embedding.fasttext import BengaliFasttext\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Exploring Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Original dataset shape: (41907, 6)\n",
      "Augmented dataset shape: (6081, 3)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the datasets\n",
    "print(\"Loading datasets...\")\n",
    "original_cleaned_df = pd.read_csv(\"../../dataset/cleaned/original_cleaned.csv\")\n",
    "only_augmented_cleaned_df = pd.read_csv(\"../../dataset/cleaned/only_augmented.csv\")\n",
    "\n",
    "print(f\"Original dataset shape: {original_cleaned_df.shape}\")\n",
    "print(f\"Augmented dataset shape: {only_augmented_cleaned_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th>comment react number</th>\n",
       "      <th>label</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>হালার পুত মদ খাওয়ার সময় রাতের বেলা মদ খাই দি...</td>\n",
       "      <td>Actor</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sexual</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ঘরে শুট কেমন লেগেছে ক্যামেরাতে</td>\n",
       "      <td>Singer</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>not bully</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>অরে বাবা টা পাগল</td>\n",
       "      <td>Actor</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>not bully</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ক্যাপ্টেন অফ বাংলাদেশ</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>not bully</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>পটকা মাছ</td>\n",
       "      <td>Politician</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>troll</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment    Category  Gender   \n",
       "0  হালার পুত মদ খাওয়ার সময় রাতের বেলা মদ খাই দি...       Actor  Female  \\\n",
       "1                     ঘরে শুট কেমন লেগেছে ক্যামেরাতে      Singer    Male   \n",
       "2                                   অরে বাবা টা পাগল       Actor  Female   \n",
       "3                              ক্যাপ্টেন অফ বাংলাদেশ      Sports    Male   \n",
       "4                                           পটকা মাছ  Politician    Male   \n",
       "\n",
       "   comment react number      label  text_length  \n",
       "0                   1.0     sexual          128  \n",
       "1                   2.0  not bully           30  \n",
       "2                   2.0  not bully           16  \n",
       "3                   0.0  not bully           21  \n",
       "4                   0.0      troll            8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of original dataset\n",
    "original_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label Mapping and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the labels for binary classification\n",
    "# \"not bully\" = 0, all other categories = 1\n",
    "def map_to_binary(label):\n",
    "    if label == \"not bully\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "original_cleaned_df[\"label_encoded\"] = original_cleaned_df[\"label\"].apply(map_to_binary)\n",
    "only_augmented_cleaned_df[\"label_encoded\"] = only_augmented_cleaned_df[\"label\"].apply(map_to_binary)\n",
    "\n",
    "# Create a human-readable binary label for visualization\n",
    "original_cleaned_df[\"binary_label\"] = original_cleaned_df[\"label_encoded\"].map({0: \"not bully\", 1: \"bully\"})\n",
    "only_augmented_cleaned_df[\"binary_label\"] = only_augmented_cleaned_df[\"label_encoded\"].map({0: \"not bully\", 1: \"bully\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of binary labels\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=\"binary_label\", data=original_cleaned_df, palette=\"viridis\")\n",
    "plt.title(\"Distribution of Binary Labels in Original Dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting and Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original dataset into train and test sets\n",
    "X = original_cleaned_df[\"comment\"]\n",
    "y = original_cleaned_df[\"label_encoded\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size before augmentation: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add augmented data to the training set\n",
    "X_aug = only_augmented_cleaned_df[\"text\"]\n",
    "y_aug = only_augmented_cleaned_df[\"label_encoded\"]\n",
    "\n",
    "# Concatenate original training data with augmented data\n",
    "X_train_augmented = pd.concat([X_train, X_aug])\n",
    "y_train_augmented = pd.concat([y_train, y_aug])\n",
    "\n",
    "print(f\"Training set size after augmentation: {len(X_train_augmented)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the class distribution before and after augmentation\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x=y_train, palette=\"viridis\")\n",
    "plt.title(\"Class Distribution in Original Training Set\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x=y_train_augmented, palette=\"viridis\")\n",
    "plt.title(\"Class Distribution After Augmentation\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Tokenization and Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SentencepieceTokenizer and BengaliFasttext\n",
    "print(\"Initializing tokenizer and word embedding model...\")\n",
    "sp_tokenizer = SentencepieceTokenizer()\n",
    "fasttext_model = BengaliFasttext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_vectorize(text):\n",
    "    # Tokenize the text\n",
    "    tokens = sp_tokenizer.tokenize(text)\n",
    "\n",
    "    # Get vector for each token and average them\n",
    "    vectors = [\n",
    "        fasttext_model.get_word_vector(token) for token in tokens if token.strip()\n",
    "    ]\n",
    "\n",
    "    # If no valid vectors, return zeros\n",
    "    if not vectors:\n",
    "        return np.zeros(300)  # FastText typically uses 300-dimensional vectors\n",
    "\n",
    "    # Average the vectors\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenization and vectorization to training data\n",
    "print(\"Vectorizing training data...\")\n",
    "start_time = time.time()\n",
    "X_train_vectors = np.array([tokenize_and_vectorize(text) for text in X_train_augmented])\n",
    "print(\n",
    "    f\"Training data vectorization completed in {time.time() - start_time:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing testing data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVectorizing testing data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_test_vectors = np.array([tokenize_and_vectorize(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mX_test\u001b[49m])\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting data vectorization completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply tokenization and vectorization to testing data\n",
    "print(\"Vectorizing testing data...\")\n",
    "start_time = time.time()\n",
    "X_test_vectors = np.array([tokenize_and_vectorize(text) for text in X_test])\n",
    "print(f\"Testing data vectorization completed in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Training Random Forest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and train Random Forest classifier\n",
    "print(\"Training Random Forest model...\")\n",
    "# Parameters optimized for text embeddings\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,  # More trees for better performance\n",
    "    max_depth=None,  # Allow trees to grow fully\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",  # Common choice for high-dimensional data\n",
    "    bootstrap=True,\n",
    "    class_weight=\"balanced\",  # Handle class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Use all processors\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "rf_model.fit(X_train_vectors, y_train_augmented)\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Model trained in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation - Basic Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and calculate basic metrics\n",
    "print(\"Evaluating model...\")\n",
    "y_pred = rf_model.predict(X_test_vectors)\n",
    "\n",
    "# Calculate basic metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Bully\", \"Bully\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]  # Normalize\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Not Bully\", \"Bully\"],\n",
    "    yticklabels=[\"Not Bully\", \"Bully\"],\n",
    ")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\n",
    "        \"Feature\": [f\"Feature_{i}\" for i in range(X_train_vectors.shape[1])],\n",
    "        \"Importance\": rf_model.feature_importances_,\n",
    "    }\n",
    ")\n",
    "feature_importance = feature_importance.sort_values(\"Importance\", ascending=False).head(\n",
    "    20\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance, palette=\"viridis\")\n",
    "plt.title(\"Top 20 Important Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ROC Curve Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve and AUC\n",
    "y_score = rf_model.predict_proba(X_test_vectors)[:, 1]  # Probability of being \"bully\"\n",
    "\n",
    "# Calculate ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Precision-Recall Curve Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "avg_precision = precision_score(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall, precision, color='blue', lw=2, \n",
    "         label=f'Precision-Recall curve (AP = {avg_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Summary and Saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "print(\"Model Summary:\")\n",
    "print(f\"Total samples in training set (with augmentation): {len(X_train_augmented)}\")\n",
    "print(f\"Total samples in test set: {len(X_test)}\")\n",
    "print(f\"Number of features (vector dimension): {X_train_vectors.shape[1]}\")\n",
    "print(f\"Final model accuracy on test set: {accuracy:.4f}\")\n",
    "print(f\"Training time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model if needed\n",
    "# import joblib\n",
    "print(f\"Total samples in training set (with augmentation): {len(X_train_augmented)}\")\n",
    "print(f\"Total samples in test set: {len(X_test)}\")\n",
    "print(f\"Number of features (vector dimension): {X_train_vectors.shape[1]}\")\n",
    "print(f\"Final model accuracy on test set: {accuracy:.4f}\")\n",
    "print(f\"Training time: {training_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
