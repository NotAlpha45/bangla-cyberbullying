{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bangla Cyberbullying Classification with LSTM\n",
    "\n",
    "This notebook implements an LSTM model for multi-class classification of Bangla cyberbullying text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from bnlp import SentencepieceTokenizer\n",
    "from bnlp.embedding.fasttext import BengaliFasttext\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "# Import deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Exploring Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "original_cleaned_df = pd.read_csv(\"../../dataset/cleaned/original_cleaned.csv\")\n",
    "\n",
    "print(f\"Original dataset shape: {original_cleaned_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of original dataset\n",
    "original_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label Mapping and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the labels for the dataset\n",
    "label_mapping = {\"not bully\": 0, \"troll\": 1, \"sexual\": 2, \"religious\": 3, \"threat\": 4}\n",
    "\n",
    "original_cleaned_df[\"label_encoded\"] = original_cleaned_df[\"label\"].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of labels\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.countplot(x=\"label\", data=original_cleaned_df, palette=\"viridis\")\n",
    "plt.title(\"Distribution of Labels in Original Dataset\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original dataset into train and test sets\n",
    "X = original_cleaned_df[\"comment\"]\n",
    "y = original_cleaned_df[\"label_encoded\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Convert to one-hot encoding for LSTM model\n",
    "y_train_cat = to_categorical(y_train, num_classes=5)\n",
    "y_test_cat = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the class distribution in the training set\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.countplot(x=y_train, palette=\"viridis\")\n",
    "plt.title(\"Class Distribution in Training Set\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Tokenization and Processing for LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LSTM, we need to tokenize and pad sequences\n",
    "print(\"Tokenizing and preparing sequences...\")\n",
    "\n",
    "# Set parameters for tokenization\n",
    "MAX_FEATURES = 50000  # Maximum number of words to keep based on word frequency\n",
    "MAX_SEQUENCE_LENGTH = 200  # Pad or truncate all sentences to this length\n",
    "\n",
    "# Initialize and fit the tokenizer\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Get vocabulary size and word index\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding token\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "\n",
    "# Convert texts to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "print(f\"Training data shape after padding: {X_train_pad.shape}\")\n",
    "print(f\"Testing data shape after padding: {X_test_pad.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load pre-trained word embeddings from BengaliFasttext\n",
    "print(\"Loading FastText word vectors...\")\n",
    "fasttext_model = BengaliFasttext()\n",
    "EMBEDDING_DIM = 300  # FastText typically uses 300-dimensional vectors\n",
    "\n",
    "# Create an embedding matrix for the vocabulary\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= MAX_FEATURES:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = fasttext_model.get_word_vector(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "print(f\"Created embedding matrix of shape: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building and Training LSTM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and build LSTM model\n",
    "print(\"Building LSTM model...\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add embedding layer - either random initialization or pre-trained\n",
    "model.add(Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    input_length=MAX_SEQUENCE_LENGTH,\n",
    "    weights=[embedding_matrix],  # Use pre-trained embeddings\n",
    "    trainable=False  # Keep embeddings fixed\n",
    "))\n",
    "\n",
    "# Add spatial dropout to prevent overfitting\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "\n",
    "# Add LSTM layer\n",
    "model.add(LSTM(units=128, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(LSTM(units=64, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(5, activation='softmax'))  # 5 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callbacks for training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='../../models/lstm/best_lstm_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training LSTM model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train_cat,\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Model trained in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation - Basic Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and calculate basic metrics\n",
    "print(\"Evaluating model...\")\n",
    "y_pred_probs = model.predict(X_test_pad)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_test_labels = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "# Calculate basic metrics\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "precision = precision_score(y_test_labels, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test_labels, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_test_labels, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred, target_names=list(label_mapping.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test_labels, y_pred)\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]  # Normalize\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=list(label_mapping.keys()),\n",
    "    yticklabels=list(label_mapping.keys()),\n",
    ")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyzing Model Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze incorrect predictions\n",
    "def analyze_misclassifications(X_test, y_true, y_pred, tokenizer, n_samples=10):\n",
    "    # Find indices of misclassified examples\n",
    "    misclassified_idxs = np.where(y_true != y_pred)[0]\n",
    "    \n",
    "    if len(misclassified_idxs) == 0:\n",
    "        print(\"No misclassifications found.\")\n",
    "        return\n",
    "    \n",
    "    # Select a random sample of misclassified examples\n",
    "    sample_idxs = np.random.choice(misclassified_idxs, min(n_samples, len(misclassified_idxs)), replace=False)\n",
    "    \n",
    "    # Create a mapping from index to label\n",
    "    idx_to_label = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    # Print details of misclassified examples\n",
    "    print(\"\\nSample of misclassified texts:\")\n",
    "    for i, idx in enumerate(sample_idxs):\n",
    "        text = X_test.iloc[idx]\n",
    "        true_label = idx_to_label[y_true[idx]]\n",
    "        pred_label = idx_to_label[y_pred[idx]]\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {text[:100]}...\" if len(text) > 100 else f\"Text: {text}\")\n",
    "        print(f\"True Label: {true_label}\")\n",
    "        print(f\"Predicted Label: {pred_label}\")\n",
    "\n",
    "# Analyze misclassifications\n",
    "analyze_misclassifications(X_test, y_test_labels, y_pred, tokenizer, n_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ROC Curve Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve and AUC for each class\n",
    "# Binarize the output for ROC curve\n",
    "y_test_bin = y_test_cat\n",
    "y_score = y_pred_probs\n",
    "\n",
    "# Calculate ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "colors = cycle([\"blue\", \"red\", \"green\", \"purple\", \"orange\"])\n",
    "class_names = list(label_mapping.keys())\n",
    "\n",
    "for i, color, class_name in zip(range(5), colors, class_names):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=2,\n",
    "        label=f\"ROC curve of {class_name} (area = {roc_auc[i]:.2f})\",\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Multi-class ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Precision-Recall Curve Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision-Recall curve and average precision for each class\n",
    "precision = {}\n",
    "recall = {}\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, color, class_name in zip(range(5), colors, class_names):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    plt.plot(\n",
    "        recall[i],\n",
    "        precision[i],\n",
    "        color=color,\n",
    "        lw=2,\n",
    "        label=f\"Precision-Recall curve of {class_name}\",\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Multi-class Precision-Recall Curve\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Summary and Saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "print(\"LSTM Classification Model Summary:\")\n",
    "print(f\"Total samples in training set: {len(X_train)}\")\n",
    "print(f\"Total samples in test set: {len(X_test)}\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Sequence length: {MAX_SEQUENCE_LENGTH}\")\n",
    "print(f\"Embedding dimension: {EMBEDDING_DIM}\")\n",
    "print(f\"Final model accuracy on test set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"../../models/lstm/multiclass_no_augment_lstm.h5\")\n",
    "\n",
    "# Save the tokenizer\n",
    "import pickle\n",
    "with open(\"../../models/lstm/tokenizer.pickle\", \"wb\") as handle\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Model and tokenizer saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
